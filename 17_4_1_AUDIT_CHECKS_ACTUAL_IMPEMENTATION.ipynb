{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z37_f47jpNSG"
      },
      "outputs": [],
      "source": [
        "# prod.csv\n",
        "# prod_id,prod_name,prod_price,prod_category\n",
        "# 101,Laptop,1200,Electronics\n",
        "# 102,Desk Chair,150,Furniture\n",
        "# 103,Notebook,5,Stationery\n",
        "\n",
        "#emp.csv\n",
        "# emp_id,emp_name,emp_salary,emp_department\n",
        "# 1,John Doe,50000,HR\n",
        "# 2,Jane Smith,60000,Finance\n",
        "# 3,Bob Johnson,55000,IT\n",
        "\n",
        "\n",
        "# DROP TABLE NEXUS.TEMP.EMP_TAB;\n",
        "# DROP TABLE NEXUS.TEMP.PROD_TAB;\n",
        "#\n",
        "#\n",
        "# CREATE OR REPLACE TABLE NEXUS.TEMP.EMP_TAB (\n",
        "# \tEMP_ID NUMBER(38,0),\n",
        "# \tEMP_NAME VARCHAR(16777216),\n",
        "# \tEMP_SALARY NUMBER(38,0),\n",
        "# \tEMP_DEPARTMENT VARCHAR(16777216)\n",
        "# );\n",
        "#\n",
        "#\n",
        "# CREATE OR REPLACE  TABLE NEXUS.TEMP.PROD_TAB (\n",
        "# \tPROD_ID NUMBER(38,0),\n",
        "# \tPROD_NAME VARCHAR(16777216),\n",
        "# \tPROD_PRICE NUMBER(38,0),\n",
        "# \tPROD_CATEGORY VARCHAR(16777216)\n",
        "# );\n",
        "\n",
        "\n",
        "import os\n",
        "import snowflake.connector\n",
        "import boto3\n",
        "from botocore.exceptions import ClientError\n",
        "import pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "s3_resource = boto3.resource('s3')\n",
        "s3_client = boto3.client('s3')\n",
        "\n",
        "CEDL_HOME = os.environ['CEDL_HOME']\n",
        "nexus_connectionProfile = CEDL_HOME + '/etc/.sf.nexus.profile'\n",
        "s3_connectionProfile = CEDL_HOME + '/etc/.s3_connection_profile'\n",
        "\n",
        "\n",
        "def create_snowflake_connection():\n",
        "    try:\n",
        "        pathExist = os.path.exists(nexus_connectionProfile)\n",
        "        if (not pathExist):\n",
        "            print('The profile {} doesn''t exist'.format(nexus_connectionProfile))\n",
        "            exit(1)\n",
        "        profileFile = open(nexus_connectionProfile)\n",
        "        for line in profileFile:\n",
        "            if (line.split('=')[0] == 'snowflakeAccount'):\n",
        "                snowflakeAccount = line.split('=')[1].replace('\\n', '')\n",
        "            elif (line.split('=')[0] == 'snowflakeUsername'):\n",
        "                snowflakeUsername = line.split('=')[1].replace('\\n', '')\n",
        "            elif (line.split('=')[0] == 'snowflakePassword'):\n",
        "                snowflakePassword = line.split('=')[1].replace('\\n', '')\n",
        "            elif (line.split('=')[0] == 'snowflakeRole'):\n",
        "                snowflakeRole = line.split('=')[1].replace('\\n', '')\n",
        "            elif (line.split('=')[0] == 'snowflakeDBName'):\n",
        "                snowflakeDBName = line.split('=')[1].replace('\\n', '')\n",
        "            elif (line.split('=')[0] == 'snowflakeWarehouse'):\n",
        "                snowflakeWarehouse = line.split('=')[1].replace('\\n', '')\n",
        "            else:\n",
        "                pass\n",
        "        profileFile.close()\n",
        "        if (len(snowflakeAccount) == 0 or len(snowflakeUsername) == 0 or len(snowflakePassword) == 0 or len(\n",
        "                snowflakeRole) == 0 or len(snowflakeDBName) == 0 or len(snowflakeWarehouse) == 0):\n",
        "            print('some parameters are missing from {}'.format(nexus_connectionProfile))\n",
        "            exit(1)\n",
        "        conn = snowflake.connector.connect(user=snowflakeUsername, password=snowflakePassword, account=snowflakeAccount,\n",
        "                            warehouse=snowflakeWarehouse, database=snowflakeDBName)\n",
        "        print(\"connected to SNOWFLAKE Database.\")\n",
        "    except snowflake.connector.Error as e:\n",
        "        print('Error connecting to SNOWFLAKE Database - {}'.format(e))\n",
        "        exit(1)\n",
        "    return conn\n",
        "\n",
        "def list_objects_in_bucket(bucket_name, prefix=''):\n",
        "    s3 = boto3.client('s3')\n",
        "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
        "    object_keys = [obj['Key'] for obj in response.get('Contents', [])]\n",
        "    return object_keys\n",
        "\n",
        "def copy_csv_file_to_snowflake(connection, database, schema, table_name, s3_bucket, s3_file_path):\n",
        "    fully_qualified_table_name = f'\"{database}\".\"{schema}\".\"{table_name}\"'\n",
        "    s3_full_path = f'{s3_bucket}/{s3_file_path}'\n",
        "\n",
        "    print(f's3_full_path {s3_full_path}')\n",
        "\n",
        "    # Copy the data directly from the S3 path into the Snowflake table\n",
        "    copy_sql = f\"\"\"\n",
        "        COPY INTO {fully_qualified_table_name}\n",
        "        FROM '{s3_full_path}'\n",
        "        FILE_FORMAT = (TYPE = CSV FIELD_OPTIONALLY_ENCLOSED_BY='\"' SKIP_HEADER=1)\n",
        "        ON_ERROR = 'CONTINUE';  -- Continue loading even if there are errors\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Executing COPY command for file: {s3_full_path}\")\n",
        "    connection.cursor().execute(copy_sql)\n",
        "    connection.commit()\n",
        "\n",
        "    print(f\"Data loaded into table {fully_qualified_table_name} from file {s3_full_path}\")\n",
        "\n",
        "    # Perform audit checks\n",
        "    s3_bucket = 'vnsny-das-staging-test'\n",
        "    path_part = os.path.relpath(s3_full_path, '@NEXUS.JMAN.STAGE_HOME')\n",
        "    #path_part_with_slash = os.path.join('/', path_part)\n",
        "    #s3_full_path = path_part_with_slash\n",
        "    s3_full_path = path_part\n",
        "\n",
        "    audit_check_results = perform_audit_checks(connection, database, schema, table_name, s3_bucket, s3_full_path)\n",
        "\n",
        "    for check, result in audit_check_results.items():\n",
        "        print(f\"{check}: {'Passed' if result else 'Failed'}\")\n",
        "\n",
        "def perform_audit_checks(connection, database, schema, table_name, s3_bucket, s3_file_path):\n",
        "    fully_qualified_table_name = f'\"{database}\".\"{schema}\".\"{table_name}\"'\n",
        "\n",
        "    # Check 1: Compare row counts\n",
        "    snowflake_row_count = get_snowflake_row_count(connection, fully_qualified_table_name)\n",
        "    print(f\" snowflake_row_count = > {fully_qualified_table_name}, {snowflake_row_count}\")\n",
        "    s3_row_count = get_s3_row_count(s3_bucket, s3_file_path)\n",
        "    print(f\" s3_row_count = >  {s3_row_count}\")\n",
        "    check1 = snowflake_row_count == s3_row_count\n",
        "\n",
        "\n",
        "    # Check 2: Compare column names\n",
        "    snowflake_columns = get_snowflake_columns(connection, fully_qualified_table_name)\n",
        "    s3_columns = get_s3_columns(s3_bucket, s3_file_path)\n",
        "    print(\"\\n\")\n",
        "    print(\"check 2: Compare column names\")\n",
        "    print(f'snowflake_columns - > {snowflake_columns}')\n",
        "    print(f's3_columns - > {s3_columns}')\n",
        "    check2 = snowflake_columns == s3_columns\n",
        "    print(f\"Check 2 {check2}\")\n",
        "\n",
        "    return {'Row Count Match': check1, 'Column Names Match': check2}\n",
        "\n",
        "def get_snowflake_row_count(connection, table_name):\n",
        "    query = f\"SELECT COUNT(*) FROM {table_name}\"\n",
        "    result = connection.cursor().execute(query).fetchone()\n",
        "    return result[0]\n",
        "\n",
        "def get_snowflake_columns(connection, table_name):\n",
        "    query = f\"DESCRIBE TABLE {table_name}\"\n",
        "    result = connection.cursor().execute(query).fetchall()\n",
        "    print(f\"{query}\")\n",
        "    print(result)\n",
        "    print(\"Column headers from table \\n\")\n",
        "    xx_temp = [row[0].lower().strip() for row in result]\n",
        "    xx = \",\".join(xx_temp)\n",
        "    print (xx)\n",
        "    print(\"\\n\")\n",
        "    return xx\n",
        "\n",
        "    non_empty_lines = [line for line in csv_data.split('\\n') if line.strip()]\n",
        "\n",
        "def get_s3_row_count(s3_bucket, s3_file_path):\n",
        "    print(f\"Inside get_s3_row_count {s3_bucket},{s3_file_path}\")\n",
        "    s3 = boto3.client('s3')\n",
        "    s3_object = s3.get_object(Bucket=s3_bucket, Key=s3_file_path)\n",
        "    csv_data = s3_object['Body'].read().decode('utf-8')\n",
        "    non_empty_lines = [line for line in csv_data.split('\\n') if line.strip()]\n",
        "    return len(non_empty_lines) - 1  # Exclude header\n",
        "\n",
        "def get_s3_columns(s3_bucket, s3_file_path):\n",
        "    s3 = boto3.client('s3')\n",
        "    s3_object = s3.get_object(Bucket=s3_bucket, Key=s3_file_path)\n",
        "    csv_header = s3_object['Body'].read().decode('utf-8').split('\\n')[0]\n",
        "    print(\"\\n\")\n",
        "    print(f\"Column headers from S3  {s3_bucket},{s3_file_path}\\n\")\n",
        "    print(csv_header)\n",
        "    print(\"\\n\")\n",
        "    csv_header_temp = [x.strip() for x in csv_header.split(',')]\n",
        "    csv_header = \",\".join(csv_header_temp)\n",
        "    return csv_header\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Snowflake connection parameters\n",
        "    snowflake_config = {\n",
        "        'warehouse': 'DAS_BAT_WH_DEV',\n",
        "        'database': 'NEXUS',\n",
        "        'schema': 'TEMP',\n",
        "    }\n",
        "\n",
        "    # Replace these values with your actual S3 and Snowflake configurations\n",
        "    s3_bucket = '@NEXUS.JMAN.STAGE_HOME'\n",
        "    s3_prefix = 'SRCFILES/TEST'\n",
        "\n",
        "    print('Objects in the bucket are ......')\n",
        "    objects = list_objects_in_bucket('vnsny-das-staging-test', s3_prefix)\n",
        "\n",
        "    if objects:\n",
        "        print(\"Objects in the S3 bucket:\")\n",
        "        for obj in objects:\n",
        "            print(obj)\n",
        "    else:\n",
        "        print(\"No objects found in the S3 bucket.\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Specify the Snowflake tables and their corresponding CSV files\n",
        "    table_mapping = {\n",
        "        'EMP_TAB': 'emp.csv',\n",
        "        'PROD_TAB': 'prod.csv',\n",
        "    }\n",
        "\n",
        "    # Create a Snowflake connection\n",
        "    snowflake_connection = create_snowflake_connection()\n",
        "\n",
        "    # Copy CSV files from S3 into the corresponding Snowflake tables\n",
        "    for table_name, file_name in table_mapping.items():\n",
        "        copy_csv_file_to_snowflake(snowflake_connection, snowflake_config['database'], snowflake_config['schema'], table_name, s3_bucket, f'{s3_prefix}/{file_name}')\n",
        "\n",
        "    # Close the Snowflake connection\n",
        "    snowflake_connection.close()\n"
      ]
    }
  ]
}